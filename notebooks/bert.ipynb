{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "NUM_LABELS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "DR_RATE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4846, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  target\n",
       "0  According to Gran , the company has no plans t...       0\n",
       "1  Technopolis plans to develop in stages an area...       0\n",
       "2  The international electronic industry company ...       2\n",
       "3  With the new production plant the company woul...       1\n",
       "4  According to the company 's updated strategy f...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news.csv', encoding='latin-1', header=None)\n",
    "df.columns = ['target','title']\n",
    "df = df[['title','target']]\n",
    "\n",
    "label_enc = {'neutral':0,'positive':1,'negative':2}\n",
    "df.target.replace(label_enc, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplitcated: 6\n"
     ]
    }
   ],
   "source": [
    "print('Duplitcated:', df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinBERT Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = 'yiyanghkust/finbert-tone'\n",
    "finbert = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "nlp = pipeline('sentiment-analysis', model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Process without label encoding\n",
    "preds = [str(result['label']).lower() for result in nlp(df.title.tolist())]\n",
    "print('Accuracy:', round(accuracy_score(df.target.tolist(), preds), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
    "from nlp import load_dataset\n",
    "from IPython.display import clear_output\n",
    "# from urllib import request\n",
    "# request.urlretrieve('https://drive.google.com/uc?id=11_M4ootuT7I1G0RlihcC0cA3Elqotlc-', 'imdbs.csv')\n",
    "\n",
    "dataset = load_dataset('csv', data_files='./imdbs.csv', split='train')\n",
    "dataset = dataset.train_test_split(test_size=0.3)\n",
    "train_set = dataset['train']\n",
    "test_set = dataset['test']\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    return tokenizer(data['text'], padding=True, truncation=True)\n",
    "\n",
    "train_set = train_set.map(preprocess, batched=True, batch_size=len(train_set))\n",
    "test_set = test_set.map(preprocess, batched=True, batch_size=len(test_set))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_format('torch', columns=['input_ids','attention_mask','label'])\n",
    "test_set.set_format('torch', columns=['input_ids','attention_mask','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 2\n",
    "warmup_steps = 500\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_dir='./logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "model.to(device)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 70\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991753dc60e245bbac5d53f27e9647d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c723d4f01b492f98f35865ae5eacb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6928791403770447, 'eval_runtime': 8.6955, 'eval_samples_per_second': 3.45, 'eval_steps_per_second': 0.46, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd03fe5eb5964a77b2a45b2cc4c4d91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6928918361663818, 'eval_runtime': 10.6884, 'eval_samples_per_second': 2.807, 'eval_steps_per_second': 0.374, 'epoch': 2.0}\n",
      "{'train_runtime': 217.4936, 'train_samples_per_second': 0.644, 'train_steps_per_second': 0.083, 'train_loss': 0.7065895398457845, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=0.7065895398457845, metrics={'train_runtime': 217.4936, 'train_samples_per_second': 0.644, 'train_steps_per_second': 0.083, 'train_loss': 0.7065895398457845, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b668c9ef618146bda28001158c30eed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6928918361663818,\n",
       " 'eval_runtime': 11.2858,\n",
       " 'eval_samples_per_second': 2.658,\n",
       " 'eval_steps_per_second': 0.354,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = {\n",
    "    'bert_base': 'bert-base-uncased',\n",
    "    'bert_large': 'bert-large-uncased',\n",
    "    'finbert': 'ProsusAI/finbert',\n",
    "    'finbert_tone': 'yiyanghkust/finbert-pretrain',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \"\"\" Financial News Sentiment Corpus Dataset \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int, num_labels: int):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.num_labels = num_labels\n",
    "        self.title = self.df.title\n",
    "        self.target = self.df.target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = self.title[index]\n",
    "        target = self.target[index]\n",
    "        inputs = self.bert_tokenize(title)\n",
    "        inputs.update({'targets': self.one_hot_encoding(target)})\n",
    "        return inputs\n",
    "\n",
    "    def bert_tokenize(self, text):\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            text=text,\n",
    "            text_pair=None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return encoded_dict\n",
    "\n",
    "    def one_hot_encoding(self, label):\n",
    "        one_hot = F.one_hot(torch.arange(self.num_labels))\n",
    "        return one_hot[label].to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=VALID_SPLIT, stratify=df.target)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = dict()\n",
    "valid_datasets = dict()\n",
    "\n",
    "for name, path in MODEL_NAMES.items():\n",
    "    tokenizer = BertTokenizer.from_pretrained(path)\n",
    "    train_datasets[name] = NewsDataset(train_df, tokenizer, MAX_LEN, NUM_LABELS)\n",
    "    valid_datasets[name] = NewsDataset(valid_df, tokenizer, MAX_LEN, NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in MODEL_NAMES.items():\n",
    "    tokens = train_datasets[name].__getitem__(0)\n",
    "    model = BertModel.from_pretrained(MODEL_NAMES['bert_base'], output_hidden_states=True)\n",
    "    result = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_datasets['bert_base'].__getitem__(0)\n",
    "del test_data['targets']\n",
    "result = model(**test_data)\n",
    "last_hidden_state, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_datasets['bert_base'].__getitem__(0)\n",
    "model = BertModel.from_pretrained(MODEL_NAMES['bert_base'], output_hidden_states=True)\n",
    "result = model(test_data['input_ids'],attention_mask=test_data['attention_mask'])\n",
    "last_hidden_state, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBaseModel(nn.Module):\n",
    "    def __init__(self, dropout: float, num_labels: int):\n",
    "        super(BertBaseModel, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        output = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('mps')\n",
    "model = BertBaseModel(DR_RATE, NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbedding(nn.Module):\n",
    "    def __init__(self, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \"\"\" Financial News Sentiment Corpus Dataset \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int, num_labels: int):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.num_labels = num_labels\n",
    "        self.title = self.df.title\n",
    "        self.target = self.df.target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = self.title[index]\n",
    "        target = self.target[index]\n",
    "        inputs = self.bert_tokenize(title)\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs['token_type_ids'].flatten(),\n",
    "            'targets': self.one_hot_encoding(target),\n",
    "        }\n",
    "\n",
    "    def bert_tokenize(self, text):\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            text=text,\n",
    "            text_pair=None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return encoded_dict\n",
    "\n",
    "    def one_hot_encoding(self, label):\n",
    "        one_hot = F.one_hot(torch.arange(self.num_labels))\n",
    "        return one_hot[label].to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=VALID_SPLIT, stratify=df.target)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(train_df, tokenizer, MAX_LEN, NUM_LABELS)\n",
    "valid_dataset = NewsDataset(val_df, tokenizer, MAX_LEN, NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-large-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained(MODEL_NAME, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2293, 3000, 102, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I love Paris'\n",
    "tokens = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=7, padding='max_length', truncation=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.tensor(tokens['input_ids']).unsqueeze(0)\n",
    "attention_mask = torch.tensor(tokens['attention_mask']).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1045, 2293, 3000,  102,    0,    0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(token_ids,attention_mask=attention_mask)\n",
    "hidden_states, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 1024])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "FINBERT = 'ProsusAI/finbert'\n",
    "finbert = BertModel.from_pretrained(FINBERT, output_hidden_states=True)\n",
    "fintokenizer = BertTokenizer.from_pretrained(FINBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = finbert(token_ids,attention_mask=attention_mask)\n",
    "hidden_states, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3517,  0.8137, -0.9715,  ..., -1.2517, -0.5206,  0.5874],\n",
       "         [ 0.7348,  1.1075,  0.0664,  ..., -0.7516, -0.4270,  0.2203],\n",
       "         [ 0.9962,  1.3483,  0.3890,  ..., -0.9823,  0.1299, -0.2494],\n",
       "         ...,\n",
       "         [ 0.3348,  0.3485,  0.0019,  ..., -0.2372, -0.6656, -0.1062],\n",
       "         [ 0.2788,  0.7250,  0.1129,  ..., -0.3339, -0.3293,  0.1269],\n",
       "         [ 0.3271,  0.4002,  0.0916,  ..., -0.2062, -0.3955, -0.0705]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4045, -0.6752, -0.3544,  ...,  0.3486,  0.8672,  0.8592],\n",
       "         [-1.2629,  0.2834,  0.7925,  ...,  0.3055,  0.4203,  1.9711],\n",
       "         [-0.3013, -0.6540, -0.3854,  ..., -0.3721,  1.0705,  1.1328],\n",
       "         ...,\n",
       "         [ 1.0212, -0.9028,  0.7644,  ..., -0.5486,  0.2132,  1.7447],\n",
       "         [ 0.5257, -0.3719,  0.1031,  ..., -0.4782,  0.5302,  1.3596],\n",
       "         [ 0.2073, -0.4750,  0.1476,  ...,  0.2096,  0.8126,  1.1591]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBaseModel(nn.Module):\n",
    "    def __init__(self, dropout: float, num_labels: int):\n",
    "        super(BertBaseModel, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        output = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('mps')\n",
    "model = BertBaseModel(DR_RATE, NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(outputs, targets):\n",
    "#     return nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "def loss_fn(outputs, targets, num_labels):\n",
    "    return nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "\n",
    "        sample = torch.tensor(padded_list)\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "model.eval()\n",
    "\n",
    "nsmc_eval_dataset = NsmcDataset(test_df)\n",
    "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in eval_loader:\n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample, label = sample.to(device), label.to(device)\n",
    "    labels = torch.tensor(label)\n",
    "    outputs = model(sample, labels=labels)\n",
    "    _, logits = outputs\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(labels)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(labels)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.encode_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "model = BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'yiyanghkust/finbert-pretrain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:15.683181Z",
     "iopub.status.busy": "2022-06-07T11:24:15.68283Z",
     "iopub.status.idle": "2022-06-07T11:24:15.687929Z",
     "shell.execute_reply": "2022-06-07T11:24:15.686764Z",
     "shell.execute_reply.started": "2022-06-07T11:24:15.683147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"text\"],padding=True,truncation=True,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:15.689724Z",
     "iopub.status.busy": "2022-06-07T11:24:15.689184Z",
     "iopub.status.idle": "2022-06-07T11:24:16.184331Z",
     "shell.execute_reply": "2022-06-07T11:24:16.183489Z",
     "shell.execute_reply.started": "2022-06-07T11:24:15.689687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:16.186329Z",
     "iopub.status.busy": "2022-06-07T11:24:16.185785Z",
     "iopub.status.idle": "2022-06-07T11:24:16.197124Z",
     "shell.execute_reply": "2022-06-07T11:24:16.196225Z",
     "shell.execute_reply.started": "2022-06-07T11:24:16.18629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok_ds = tok_ds.remove_columns('text')\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:16.198878Z",
     "iopub.status.busy": "2022-06-07T11:24:16.198626Z",
     "iopub.status.idle": "2022-06-07T11:24:16.629012Z",
     "shell.execute_reply": "2022-06-07T11:24:16.628146Z",
     "shell.execute_reply.started": "2022-06-07T11:24:16.198853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer,EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:21.590547Z",
     "iopub.status.busy": "2022-06-07T11:24:21.590179Z",
     "iopub.status.idle": "2022-06-07T11:24:21.595318Z",
     "shell.execute_reply": "2022-06-07T11:24:21.593627Z",
     "shell.execute_reply.started": "2022-06-07T11:24:21.590512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "lr = 2e-5\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:26.41555Z",
     "iopub.status.busy": "2022-06-07T11:24:26.415188Z",
     "iopub.status.idle": "2022-06-07T11:24:26.423428Z",
     "shell.execute_reply": "2022-06-07T11:24:26.422509Z",
     "shell.execute_reply.started": "2022-06-07T11:24:26.415517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:26.747349Z",
     "iopub.status.busy": "2022-06-07T11:24:26.747004Z",
     "iopub.status.idle": "2022-06-07T11:24:26.811301Z",
     "shell.execute_reply": "2022-06-07T11:24:26.810353Z",
     "shell.execute_reply.started": "2022-06-07T11:24:26.747314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*4, \n",
    "                         weight_decay=0.01, report_to='none',num_train_epochs=epochs,load_best_model_at_end = True,\n",
    "                         logging_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:27.049159Z",
     "iopub.status.busy": "2022-06-07T11:24:27.048817Z",
     "iopub.status.idle": "2022-06-07T11:24:52.596827Z",
     "shell.execute_reply": "2022-06-07T11:24:52.595962Z",
     "shell.execute_reply.started": "2022-06-07T11:24:27.049129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:24:52.598797Z",
     "iopub.status.busy": "2022-06-07T11:24:52.598429Z",
     "iopub.status.idle": "2022-06-07T11:25:00.247645Z",
     "shell.execute_reply": "2022-06-07T11:25:00.246757Z",
     "shell.execute_reply.started": "2022-06-07T11:24:52.598757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model, args, train_dataset=tok_ds['train'], eval_dataset=tok_ds['test'],\n",
    "                  tokenizer=tokz,compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:25:00.249884Z",
     "iopub.status.busy": "2022-06-07T11:25:00.249515Z",
     "iopub.status.idle": "2022-06-07T11:27:27.826609Z",
     "shell.execute_reply": "2022-06-07T11:27:27.82563Z",
     "shell.execute_reply.started": "2022-06-07T11:25:00.249848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:27.828741Z",
     "iopub.status.busy": "2022-06-07T11:27:27.828365Z",
     "iopub.status.idle": "2022-06-07T11:27:29.465175Z",
     "shell.execute_reply": "2022-06-07T11:27:29.464121Z",
     "shell.execute_reply.started": "2022-06-07T11:27:27.828691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:29.470005Z",
     "iopub.status.busy": "2022-06-07T11:27:29.469613Z",
     "iopub.status.idle": "2022-06-07T11:27:31.080255Z",
     "shell.execute_reply": "2022-06-07T11:27:31.079415Z",
     "shell.execute_reply.started": "2022-06-07T11:27:29.469969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds = trainer.predict(tok_ds['test'])\n",
    "preds = np.argmax(preds.predictions, axis=-1)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets examine what is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.081902Z",
     "iopub.status.busy": "2022-06-07T11:27:31.081547Z",
     "iopub.status.idle": "2022-06-07T11:27:31.104604Z",
     "shell.execute_reply": "2022-06-07T11:27:31.103753Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.081873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.106715Z",
     "iopub.status.busy": "2022-06-07T11:27:31.106269Z",
     "iopub.status.idle": "2022-06-07T11:27:31.120442Z",
     "shell.execute_reply": "2022-06-07T11:27:31.119582Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.106677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.124715Z",
     "iopub.status.busy": "2022-06-07T11:27:31.124183Z",
     "iopub.status.idle": "2022-06-07T11:27:31.129992Z",
     "shell.execute_reply": "2022-06-07T11:27:31.128543Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.124671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "assert len(val)==len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.133296Z",
     "iopub.status.busy": "2022-06-07T11:27:31.132851Z",
     "iopub.status.idle": "2022-06-07T11:27:31.139148Z",
     "shell.execute_reply": "2022-06-07T11:27:31.138044Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.133259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.140939Z",
     "iopub.status.busy": "2022-06-07T11:27:31.140553Z",
     "iopub.status.idle": "2022-06-07T11:27:31.152592Z",
     "shell.execute_reply": "2022-06-07T11:27:31.15157Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.1409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.154688Z",
     "iopub.status.busy": "2022-06-07T11:27:31.154279Z",
     "iopub.status.idle": "2022-06-07T11:27:31.175833Z",
     "shell.execute_reply": "2022-06-07T11:27:31.175051Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.154649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(val.label==val.preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.177471Z",
     "iopub.status.busy": "2022-06-07T11:27:31.177118Z",
     "iopub.status.idle": "2022-06-07T11:27:31.184974Z",
     "shell.execute_reply": "2022-06-07T11:27:31.183976Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.17743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.187691Z",
     "iopub.status.busy": "2022-06-07T11:27:31.187009Z",
     "iopub.status.idle": "2022-06-07T11:27:31.199507Z",
     "shell.execute_reply": "2022-06-07T11:27:31.198298Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.187653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val[val.label!=val.preds].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.201372Z",
     "iopub.status.busy": "2022-06-07T11:27:31.200807Z",
     "iopub.status.idle": "2022-06-07T11:27:31.21571Z",
     "shell.execute_reply": "2022-06-07T11:27:31.214624Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.20132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wrong=val[val.label!=val.preds]\n",
    "wrong.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding similar data to fine tune model on\n",
    "Let's find keyphrases that the current model may be confused with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:31.218153Z",
     "iopub.status.busy": "2022-06-07T11:27:31.217402Z",
     "iopub.status.idle": "2022-06-07T11:27:42.391299Z",
     "shell.execute_reply": "2022-06-07T11:27:42.390064Z",
     "shell.execute_reply.started": "2022-06-07T11:27:31.218046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:42.393664Z",
     "iopub.status.busy": "2022-06-07T11:27:42.393285Z",
     "iopub.status.idle": "2022-06-07T11:27:58.968917Z",
     "shell.execute_reply": "2022-06-07T11:27:58.968024Z",
     "shell.execute_reply.started": "2022-06-07T11:27:42.393624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:27:58.970962Z",
     "iopub.status.busy": "2022-06-07T11:27:58.970545Z",
     "iopub.status.idle": "2022-06-07T11:28:01.606693Z",
     "shell.execute_reply": "2022-06-07T11:28:01.605706Z",
     "shell.execute_reply.started": "2022-06-07T11:27:58.970903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../input/news-aggregator-dataset/uci-news-aggregator.csv\")\n",
    "print(news.shape[0])\n",
    "news=news[news.CATEGORY=='b'] #b for business\n",
    "\n",
    "news.drop(['ID','URL','CATEGORY','STORY','HOSTNAME','TIMESTAMP','PUBLISHER'],axis=1,inplace=True)\n",
    "news.rename({'TITLE':'text'},inplace=True,axis=1)\n",
    "news.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:01.60848Z",
     "iopub.status.busy": "2022-06-07T11:28:01.608104Z",
     "iopub.status.idle": "2022-06-07T11:28:53.98472Z",
     "shell.execute_reply": "2022-06-07T11:28:53.983369Z",
     "shell.execute_reply.started": "2022-06-07T11:28:01.608436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = news.text.tolist()\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:53.986704Z",
     "iopub.status.busy": "2022-06-07T11:28:53.986337Z",
     "iopub.status.idle": "2022-06-07T11:28:54.345455Z",
     "shell.execute_reply": "2022-06-07T11:28:54.34451Z",
     "shell.execute_reply.started": "2022-06-07T11:28:53.986664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Query sentences:\n",
    "queries = val.text.tolist()\n",
    "query_embeddings = embedder.encode(queries, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:54.347455Z",
     "iopub.status.busy": "2022-06-07T11:28:54.346933Z",
     "iopub.status.idle": "2022-06-07T11:28:54.353888Z",
     "shell.execute_reply": "2022-06-07T11:28:54.352479Z",
     "shell.execute_reply.started": "2022-06-07T11:28:54.347414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#https://www.sbert.net/examples/applications/semantic-search/README.html\n",
    "corpus_embeddings = corpus_embeddings.to('cuda')\n",
    "corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n",
    "\n",
    "query_embeddings = query_embeddings.to('cuda')\n",
    "query_embeddings = util.normalize_embeddings(query_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:54.355938Z",
     "iopub.status.busy": "2022-06-07T11:28:54.355577Z",
     "iopub.status.idle": "2022-06-07T11:28:54.394236Z",
     "shell.execute_reply": "2022-06-07T11:28:54.393461Z",
     "shell.execute_reply.started": "2022-06-07T11:28:54.3559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hits = util.semantic_search(query_embeddings, corpus_embeddings, score_function=util.dot_score,top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:54.396747Z",
     "iopub.status.busy": "2022-06-07T11:28:54.396255Z",
     "iopub.status.idle": "2022-06-07T11:28:54.402614Z",
     "shell.execute_reply": "2022-06-07T11:28:54.401683Z",
     "shell.execute_reply.started": "2022-06-07T11:28:54.39671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "res=[]\n",
    "for results in hits:\n",
    "    for topResults in results:\n",
    "        res.append(topResults['corpus_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:54.40834Z",
     "iopub.status.busy": "2022-06-07T11:28:54.408087Z",
     "iopub.status.idle": "2022-06-07T11:28:54.416171Z",
     "shell.execute_reply": "2022-06-07T11:28:54.415099Z",
     "shell.execute_reply.started": "2022-06-07T11:28:54.408315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final=[corpus[x] for x in res]\n",
    "final=list(set(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:54.418917Z",
     "iopub.status.busy": "2022-06-07T11:28:54.418221Z",
     "iopub.status.idle": "2022-06-07T11:28:54.425079Z",
     "shell.execute_reply": "2022-06-07T11:28:54.424164Z",
     "shell.execute_reply.started": "2022-06-07T11:28:54.418881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labelling the additional training dataset\n",
    "typically at this point we would want to hand label some data, but who has time for that? for convenience, let's just use another finbert to label these datapoints - this is sometimes called semi-supervised learning, where we get a teacher model to pseudo label an unlabelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:28:54.426938Z",
     "iopub.status.busy": "2022-06-07T11:28:54.426448Z",
     "iopub.status.idle": "2022-06-07T11:29:21.188846Z",
     "shell.execute_reply": "2022-06-07T11:29:21.18781Z",
     "shell.execute_reply.started": "2022-06-07T11:28:54.426902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available() : device=0\n",
    "else: device=-1\n",
    "\n",
    "nlp=pipeline('sentiment-analysis',model='ProsusAI/finbert',device=device)\n",
    "\n",
    "#from https://github.com/marcotcr/checklist/blob/master/notebooks/tutorials/5.%20Testing%20transformer%20pipelines.ipynb\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def batch_predict(nlp, data, batch_size=128):\n",
    "    ret = []\n",
    "    for d in chunks(data, batch_size):\n",
    "        ret.extend(nlp(d))\n",
    "    return ret\n",
    "\n",
    "def pred_and_conf(data):\n",
    "    # change format to softmax, make everything in [0.33, 0.66] range be predicted as neutral\n",
    "    preds = batch_predict(nlp, data)\n",
    "    pred=[x['label'] for x in preds]\n",
    "    conf=[x['score'] for x in preds]\n",
    "    return pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:21.19078Z",
     "iopub.status.busy": "2022-06-07T11:29:21.190433Z",
     "iopub.status.idle": "2022-06-07T11:29:21.199331Z",
     "shell.execute_reply": "2022-06-07T11:29:21.198274Z",
     "shell.execute_reply.started": "2022-06-07T11:29:21.190742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "toLabel=pd.DataFrame({'text':final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:21.201139Z",
     "iopub.status.busy": "2022-06-07T11:29:21.200742Z",
     "iopub.status.idle": "2022-06-07T11:29:24.747807Z",
     "shell.execute_reply": "2022-06-07T11:29:24.746927Z",
     "shell.execute_reply.started": "2022-06-07T11:29:21.201099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred,conf=pred_and_conf(toLabel['text'].tolist())\n",
    "\n",
    "toLabel['label'] = pred\n",
    "toLabel['conf']  = conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to training set the higher confidence ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:24.74968Z",
     "iopub.status.busy": "2022-06-07T11:29:24.749208Z",
     "iopub.status.idle": "2022-06-07T11:29:24.771783Z",
     "shell.execute_reply": "2022-06-07T11:29:24.770925Z",
     "shell.execute_reply.started": "2022-06-07T11:29:24.749643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# toTrain = toLabel\n",
    "toTrain = toLabel[toLabel.conf>0.7]\n",
    "toTrain.label = toTrain.label.replace(d)\n",
    "len(toTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:24.773715Z",
     "iopub.status.busy": "2022-06-07T11:29:24.773287Z",
     "iopub.status.idle": "2022-06-07T11:29:24.785379Z",
     "shell.execute_reply": "2022-06-07T11:29:24.784248Z",
     "shell.execute_reply.started": "2022-06-07T11:29:24.773676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "add_trn = Dataset.from_pandas(toTrain[['text','label']].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:24.787028Z",
     "iopub.status.busy": "2022-06-07T11:29:24.786689Z",
     "iopub.status.idle": "2022-06-07T11:29:24.794056Z",
     "shell.execute_reply": "2022-06-07T11:29:24.792894Z",
     "shell.execute_reply.started": "2022-06-07T11:29:24.786993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:24.796827Z",
     "iopub.status.busy": "2022-06-07T11:29:24.796013Z",
     "iopub.status.idle": "2022-06-07T11:29:24.814584Z",
     "shell.execute_reply": "2022-06-07T11:29:24.813795Z",
     "shell.execute_reply.started": "2022-06-07T11:29:24.796786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds['train'] = concatenate_datasets([ds['train'],add_trn])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:24.816221Z",
     "iopub.status.busy": "2022-06-07T11:29:24.815829Z",
     "iopub.status.idle": "2022-06-07T11:29:25.518719Z",
     "shell.execute_reply": "2022-06-07T11:29:25.517841Z",
     "shell.execute_reply.started": "2022-06-07T11:29:24.816183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we reinitialize the model and train, maybe for a longer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:25.520428Z",
     "iopub.status.busy": "2022-06-07T11:29:25.520054Z",
     "iopub.status.idle": "2022-06-07T11:29:29.25158Z",
     "shell.execute_reply": "2022-06-07T11:29:29.25072Z",
     "shell.execute_reply.started": "2022-06-07T11:29:25.520375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:29.25341Z",
     "iopub.status.busy": "2022-06-07T11:29:29.252898Z",
     "iopub.status.idle": "2022-06-07T11:29:29.257711Z",
     "shell.execute_reply": "2022-06-07T11:29:29.256684Z",
     "shell.execute_reply.started": "2022-06-07T11:29:29.253356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "lr = 2e-5\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:29.259469Z",
     "iopub.status.busy": "2022-06-07T11:29:29.259101Z",
     "iopub.status.idle": "2022-06-07T11:29:29.268212Z",
     "shell.execute_reply": "2022-06-07T11:29:29.267409Z",
     "shell.execute_reply.started": "2022-06-07T11:29:29.259435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*4, \n",
    "                         weight_decay=0.01, report_to='none',num_train_epochs=epochs,load_best_model_at_end = True,\n",
    "                         logging_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:29.269941Z",
     "iopub.status.busy": "2022-06-07T11:29:29.269574Z",
     "iopub.status.idle": "2022-06-07T11:29:29.990564Z",
     "shell.execute_reply": "2022-06-07T11:29:29.989529Z",
     "shell.execute_reply.started": "2022-06-07T11:29:29.269904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model, args, train_dataset=tok_ds['train'], eval_dataset=tok_ds['test'],\n",
    "                  tokenizer=tokz,compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:29:29.999796Z",
     "iopub.status.busy": "2022-06-07T11:29:29.99755Z",
     "iopub.status.idle": "2022-06-07T11:41:16.370224Z",
     "shell.execute_reply": "2022-06-07T11:41:16.369363Z",
     "shell.execute_reply.started": "2022-06-07T11:29:29.999751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T11:41:16.371857Z",
     "iopub.status.busy": "2022-06-07T11:41:16.371527Z",
     "iopub.status.idle": "2022-06-07T11:41:18.473259Z",
     "shell.execute_reply": "2022-06-07T11:41:18.472317Z",
     "shell.execute_reply.started": "2022-06-07T11:41:16.371822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('mldl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ae205601b6d906014fa7892090616f7e1469eb0aa86f06d2d1803a695f1eb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
