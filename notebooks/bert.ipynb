{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "VALID_SPLIT = 0.3\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "DR_RATE = 0.3\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "METRIC = 'f1'\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4840, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  According to Gran , the company has no plans t...      0\n",
       "1  Technopolis plans to develop in stages an area...      0\n",
       "2  The international electronic industry company ...      2\n",
       "3  With the new production plant the company woul...      1\n",
       "4  According to the company 's updated strategy f...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news.csv')\n",
    "LABELS = ['neutral', 'positive', 'negative']\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2873\n",
       "1    1363\n",
       "2     604\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinBERT Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = 'yiyanghkust/finbert-tone'\n",
    "finbert = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(LABELS))\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "nlp = pipeline('sentiment-analysis', model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y = df.label.replace(id2label).tolist()\n",
    "preds = [str(result['label']).lower() for result in nlp(df.text.tolist())]\n",
    "print('Accuracy:', round(accuracy_score(Y, preds), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3388, 2) (1452, 2)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from nlp import load_dataset\n",
    "from nlp.dataset_dict import DatasetDict\n",
    "from IPython.display import clear_output\n",
    "from typing import Callable, Dict\n",
    "\n",
    "dataset = load_dataset('csv', data_files='./news.csv', split='train')\n",
    "dataset = dataset.train_test_split(test_size=VALID_SPLIT)\n",
    "clear_output()\n",
    "print(dataset['train'].shape, dataset['test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(name: str) -> Callable[[DatasetDict],BatchEncoding]:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(name, problem_type='multi_label_classification')\n",
    "    clear_output()\n",
    "    return lambda examples: tokenizer(examples['text'], max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "\n",
    "def one_hot(examples: DatasetDict) -> Dict[str,np.ndarray]:\n",
    "    return {'labels':np.eye(len(LABELS))[examples['label']]}\n",
    "\n",
    "def preprocess(data: DatasetDict, name: str) -> DatasetDict:\n",
    "    encoded = data.map(tokenize(name), batched=True, remove_columns=['text'])\n",
    "    encoded = encoded.map(one_hot, remove_columns=['label'])\n",
    "    encoded.set_format('torch')\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(name: str, trainable=True) -> BertForSequenceClassification:\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path=name,\n",
    "        problem_type='multi_label_classification',\n",
    "        num_labels=len(LABELS),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,).to(device)\n",
    "    clear_output()\n",
    "\n",
    "    if not trainable:\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions[:, 0]\n",
    "    binary_predictions = [1.0 if prediction >= 3.0 else 0.0 for prediction in predictions]\n",
    "    binary_labels = [1.0 if label >= 3.0 else 0.0 for label in labels]\n",
    "    pr = metric_pearsonr.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric_f1.compute(predictions=binary_predictions, references=binary_labels)\n",
    "\n",
    "    return {\"pearsonr\": pr, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(name: str) -> Dict[str,str]:\n",
    "    required_dirs = {\n",
    "        'root':'./saved','model_root':'./saved/models','model_dir':f'./saved/models/{name}',\n",
    "        'logging_root':'./saved/logger','logging_dir':f'./saved/logger/{name}'}\n",
    "    for dir in required_dirs.values():\n",
    "        if not os.path.isdir(dir):\n",
    "            os.mkdir(dir)\n",
    "    return required_dirs\n",
    "\n",
    "def training_args(name: str) -> TrainingArguments:\n",
    "    required_dirs = make_dirs(name)\n",
    "    return TrainingArguments(\n",
    "        output_dir=required_dirs['model_dir'],\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        logging_dir=required_dirs['logging_dir'],\n",
    "        load_best_model_at_end=True,\n",
    "        label_names=LABELS,\n",
    "        metric_for_best_model=METRIC,\n",
    "    )\n",
    "\n",
    "def trainer(dataset: DatasetDict, model_name: str, model_path: str, trainable=True) -> Trainer:\n",
    "    data_loader = preprocess(dataset, model_path)\n",
    "\n",
    "    return Trainer(\n",
    "        model=model(model_path, trainable),\n",
    "        args=training_args(model_name),\n",
    "        train_dataset=data_loader['train'],\n",
    "        eval_dataset=data_loader['test']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = {\n",
    "    'bert_base': 'bert-base-uncased',\n",
    "    'bert_large': 'bert-large-uncased',\n",
    "    'finbert': 'ProsusAI/finbert',\n",
    "    'finbert_tone': 'yiyanghkust/finbert-pretrain',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_trainer = trainer(dataset, 'bert_base', MODEL_PATH['bert_base'], trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3388\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccbfd9f8d5d4dd48bdadec506eb7a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1452\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff739392152d49d898f9e16f22fda094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/bert_base/checkpoint-424\n",
      "Configuration saved in ./results/bert_base/checkpoint-424/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 126.9688, 'eval_samples_per_second': 11.436, 'eval_steps_per_second': 1.433, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results/bert_base/checkpoint-424/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'eval_f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/cuz/Documents/Github/cif/notebooks/bert.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cuz/Documents/Github/cif/notebooks/bert.ipynb#ch0000154?line=0'>1</a>\u001b[0m bert_base_trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniforge3/envs/mldl/lib/python3.8/site-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1410\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1411\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1412\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1413\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1414\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/mldl/lib/python3.8/site-packages/transformers/trainer.py:1743\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1740\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1743\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1745\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m   1746\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1747\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/mldl/lib/python3.8/site-packages/transformers/trainer.py:1916\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, epoch, metrics)\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m-> 1916\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniforge3/envs/mldl/lib/python3.8/site-packages/transformers/trainer.py:2034\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m metric_to_check\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   2033\u001b[0m     metric_to_check \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00mmetric_to_check\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 2034\u001b[0m metric_value \u001b[39m=\u001b[39m metrics[metric_to_check]\n\u001b[1;32m   2036\u001b[0m operator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgreater \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgreater_is_better \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mless\n\u001b[1;32m   2037\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2038\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbest_metric \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2039\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbest_model_checkpoint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m     \u001b[39mor\u001b[39;00m operator(metric_value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbest_metric)\n\u001b[1;32m   2041\u001b[0m ):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'eval_f1'"
     ]
    }
   ],
   "source": [
    "bert_base_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = {\n",
    "    'bert_base': 'bert-base-uncased',\n",
    "    'bert_large': 'bert-large-uncased',\n",
    "    'finbert': 'ProsusAI/finbert',\n",
    "    'finbert_tone': 'yiyanghkust/finbert-pretrain',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \"\"\" Financial News Sentiment Corpus Dataset \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int, num_labels: int):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.num_labels = num_labels\n",
    "        self.title = self.df.title\n",
    "        self.target = self.df.target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = self.title[index]\n",
    "        target = self.target[index]\n",
    "        inputs = self.bert_tokenize(title)\n",
    "        inputs.update({'targets': self.one_hot_encoding(target)})\n",
    "        return inputs\n",
    "\n",
    "    def bert_tokenize(self, text):\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            text=text,\n",
    "            text_pair=None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return encoded_dict\n",
    "\n",
    "    def one_hot_encoding(self, label):\n",
    "        one_hot = F.one_hot(torch.arange(self.num_labels))\n",
    "        return one_hot[label].to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=VALID_SPLIT, stratify=df.target)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = dict()\n",
    "valid_datasets = dict()\n",
    "\n",
    "for name, path in MODEL_NAMES.items():\n",
    "    tokenizer = BertTokenizer.from_pretrained(path)\n",
    "    train_datasets[name] = NewsDataset(train_df, tokenizer, MAX_LEN, NUM_LABELS)\n",
    "    valid_datasets[name] = NewsDataset(valid_df, tokenizer, MAX_LEN, NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in MODEL_NAMES.items():\n",
    "    tokens = train_datasets[name].__getitem__(0)\n",
    "    model = BertModel.from_pretrained(MODEL_NAMES['bert_base'], output_hidden_states=True)\n",
    "    result = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_datasets['bert_base'].__getitem__(0)\n",
    "del test_data['targets']\n",
    "result = model(**test_data)\n",
    "last_hidden_state, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_datasets['bert_base'].__getitem__(0)\n",
    "model = BertModel.from_pretrained(MODEL_NAMES['bert_base'], output_hidden_states=True)\n",
    "result = model(test_data['input_ids'],attention_mask=test_data['attention_mask'])\n",
    "last_hidden_state, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBaseModel(nn.Module):\n",
    "    def __init__(self, dropout: float, num_labels: int):\n",
    "        super(BertBaseModel, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        output = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('mps')\n",
    "model = BertBaseModel(DR_RATE, NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbedding(nn.Module):\n",
    "    def __init__(self, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    \"\"\" Financial News Sentiment Corpus Dataset \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int, num_labels: int):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.num_labels = num_labels\n",
    "        self.title = self.df.title\n",
    "        self.target = self.df.target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = self.title[index]\n",
    "        target = self.target[index]\n",
    "        inputs = self.bert_tokenize(title)\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs['token_type_ids'].flatten(),\n",
    "            'targets': self.one_hot_encoding(target),\n",
    "        }\n",
    "\n",
    "    def bert_tokenize(self, text):\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            text=text,\n",
    "            text_pair=None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return encoded_dict\n",
    "\n",
    "    def one_hot_encoding(self, label):\n",
    "        one_hot = F.one_hot(torch.arange(self.num_labels))\n",
    "        return one_hot[label].to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=VALID_SPLIT, stratify=df.target)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(train_df, tokenizer, MAX_LEN, NUM_LABELS)\n",
    "valid_dataset = NewsDataset(val_df, tokenizer, MAX_LEN, NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-large-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained(MODEL_NAME, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2293, 3000, 102, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I love Paris'\n",
    "tokens = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=7, padding='max_length', truncation=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.tensor(tokens['input_ids']).unsqueeze(0)\n",
    "attention_mask = torch.tensor(tokens['attention_mask']).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1045, 2293, 3000,  102,    0,    0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(token_ids,attention_mask=attention_mask)\n",
    "hidden_states, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 1024])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "FINBERT = 'ProsusAI/finbert'\n",
    "finbert = BertModel.from_pretrained(FINBERT, output_hidden_states=True)\n",
    "fintokenizer = BertTokenizer.from_pretrained(FINBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = finbert(token_ids,attention_mask=attention_mask)\n",
    "hidden_states, pooler_output, hidden_states = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3517,  0.8137, -0.9715,  ..., -1.2517, -0.5206,  0.5874],\n",
       "         [ 0.7348,  1.1075,  0.0664,  ..., -0.7516, -0.4270,  0.2203],\n",
       "         [ 0.9962,  1.3483,  0.3890,  ..., -0.9823,  0.1299, -0.2494],\n",
       "         ...,\n",
       "         [ 0.3348,  0.3485,  0.0019,  ..., -0.2372, -0.6656, -0.1062],\n",
       "         [ 0.2788,  0.7250,  0.1129,  ..., -0.3339, -0.3293,  0.1269],\n",
       "         [ 0.3271,  0.4002,  0.0916,  ..., -0.2062, -0.3955, -0.0705]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4045, -0.6752, -0.3544,  ...,  0.3486,  0.8672,  0.8592],\n",
       "         [-1.2629,  0.2834,  0.7925,  ...,  0.3055,  0.4203,  1.9711],\n",
       "         [-0.3013, -0.6540, -0.3854,  ..., -0.3721,  1.0705,  1.1328],\n",
       "         ...,\n",
       "         [ 1.0212, -0.9028,  0.7644,  ..., -0.5486,  0.2132,  1.7447],\n",
       "         [ 0.5257, -0.3719,  0.1031,  ..., -0.4782,  0.5302,  1.3596],\n",
       "         [ 0.2073, -0.4750,  0.1476,  ...,  0.2096,  0.8126,  1.1591]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBaseModel(nn.Module):\n",
    "    def __init__(self, dropout: float, num_labels: int):\n",
    "        super(BertBaseModel, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        output = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('mps')\n",
    "model = BertBaseModel(DR_RATE, NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(outputs, targets):\n",
    "#     return nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "def loss_fn(outputs, targets, num_labels):\n",
    "    return nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('mldl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ae205601b6d906014fa7892090616f7e1469eb0aa86f06d2d1803a695f1eb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
